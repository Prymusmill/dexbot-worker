"""
Modu≈Ç do augmentacji danych dla modeli ML.

Ten modu≈Ç zawiera funkcje do augmentacji danych, balansowania klas i generowania syntetycznych danych,
co pozwala na trenowanie modeli ML na wiƒôkszej ilo≈õci danych.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Union, Any
import os
import logging
import random
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors

# Konfiguracja logowania
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_historical_data(csv_path: Optional[str] = None, 
                         db_connection: Optional[Any] = None, 
                         min_samples: int = 100) -> pd.DataFrame:
    """
    ≈Åaduje dane historyczne z pliku CSV lub bazy danych.
    
    Args:
        csv_path: ≈öcie≈ºka do pliku CSV z danymi historycznymi
        db_connection: Po≈ÇƒÖczenie do bazy danych
        min_samples: Minimalna liczba pr√≥bek do za≈Çadowania
        
    Returns:
        pd.DataFrame: DataFrame z danymi historycznymi
    """
    data = pd.DataFrame()
    
    # Pr√≥ba za≈Çadowania danych z bazy danych
    if db_connection is not None:
        try:
            if hasattr(db_connection, 'get_all_transactions_for_ml'):
                data = db_connection.get_all_transactions_for_ml()
                logger.info(f"‚úÖ Loaded {len(data)} samples from database")
            elif hasattr(db_connection, 'connection'):
                # Pr√≥ba u≈ºycia bezpo≈õredniego po≈ÇƒÖczenia SQL
                query = """
                    SELECT * FROM transactions 
                    ORDER BY timestamp DESC 
                    LIMIT 1000
                """
                data = pd.read_sql_query(query, db_connection.connection)
                logger.info(f"‚úÖ Loaded {len(data)} samples from database using direct SQL")
        except Exception as e:
            logger.error(f"‚ùå Error loading data from database: {e}")
    
    # Je≈õli nie uda≈Ço siƒô za≈Çadowaƒá danych z bazy lub jest ich za ma≈Ço, pr√≥ba za≈Çadowania z CSV
    if len(data) < min_samples and csv_path is not None:
        try:
            if os.path.exists(csv_path):
                csv_data = pd.read_csv(csv_path)
                if 'timestamp' in csv_data.columns:
                    csv_data['timestamp'] = pd.to_datetime(csv_data['timestamp'])
                logger.info(f"‚úÖ Loaded {len(csv_data)} samples from CSV")
                
                # Je≈õli mamy ju≈º jakie≈õ dane z bazy, po≈ÇƒÖcz je z danymi z CSV
                if not data.empty:
                    # Sprawd≈∫, czy kolumny siƒô zgadzajƒÖ
                    common_cols = list(set(data.columns) & set(csv_data.columns))
                    if common_cols:
                        data = pd.concat([data, csv_data[common_cols]], ignore_index=True)
                        logger.info(f"‚úÖ Combined data: {len(data)} samples")
                    else:
                        data = csv_data
                else:
                    data = csv_data
        except Exception as e:
            logger.error(f"‚ùå Error loading data from CSV: {e}")
    
    # Je≈õli nadal mamy za ma≈Ço danych, generuj syntetyczne dane
    if len(data) < min_samples:
        logger.warning(f"‚ö†Ô∏è Not enough data: {len(data)}/{min_samples} samples")
        if not data.empty:
            # Generuj syntetyczne dane na podstawie istniejƒÖcych
            synthetic_data = generate_synthetic_data(data, min_samples - len(data))
            data = pd.concat([data, synthetic_data], ignore_index=True)
            logger.info(f"‚úÖ Generated synthetic data: {len(data)} samples total")
        else:
            # Je≈õli nie mamy ≈ºadnych danych, generuj ca≈Çkowicie losowe dane
            data = generate_random_data(min_samples)
            logger.info(f"‚úÖ Generated random data: {len(data)} samples")
    
    return data

def balance_directional_classes(df: pd.DataFrame, 
                               target_col: str = 'direction', 
                               min_samples_per_class: int = 50) -> pd.DataFrame:
    """
    Balansuje klasy w danych treningowych.
    
    Args:
        df: DataFrame z danymi treningowymi
        target_col: Nazwa kolumny zawierajƒÖcej etykiety klas
        min_samples_per_class: Minimalna liczba pr√≥bek dla ka≈ºdej klasy
        
    Returns:
        pd.DataFrame: Zbalansowany DataFrame
    """
    if df.empty or target_col not in df.columns:
        logger.warning(f"‚ö†Ô∏è Cannot balance classes: DataFrame is empty or missing target column '{target_col}'")
        return df
    
    # Sprawd≈∫ rozk≈Çad klas
    class_counts = df[target_col].value_counts()
    logger.info(f"üìä Initial class distribution: {dict(class_counts)}")
    
    # Sprawd≈∫, czy mamy wszystkie oczekiwane klasy
    expected_classes = ['long', 'short', 'hold']
    missing_classes = [cls for cls in expected_classes if cls not in class_counts.index]
    
    balanced_df = df.copy()
    
    # Dodaj brakujƒÖce klasy
    for cls in missing_classes:
        logger.warning(f"‚ö†Ô∏è Missing class: '{cls}', generating synthetic samples")
        # Generuj syntetyczne pr√≥bki dla brakujƒÖcej klasy
        if not df.empty:
            synthetic_samples = generate_synthetic_samples_for_class(df, cls, min_samples_per_class)
            balanced_df = pd.concat([balanced_df, synthetic_samples], ignore_index=True)
        else:
            # Je≈õli DataFrame jest pusty, generuj losowe pr√≥bki
            random_samples = generate_random_samples_for_class(cls, min_samples_per_class)
            balanced_df = pd.concat([balanced_df, random_samples], ignore_index=True)
    
    # Uzupe≈Çnij klasy, kt√≥re majƒÖ za ma≈Ço pr√≥bek
    for cls in class_counts.index:
        if class_counts[cls] < min_samples_per_class:
            samples_to_add = min_samples_per_class - class_counts[cls]
            logger.info(f"‚ö†Ô∏è Class '{cls}' has only {class_counts[cls]} samples, adding {samples_to_add} more")
            
            # Wybierz pr√≥bki z danej klasy
            class_samples = df[df[target_col] == cls]
            
            if len(class_samples) > 0:
                # Generuj syntetyczne pr√≥bki na podstawie istniejƒÖcych
                synthetic_samples = generate_synthetic_samples_for_class(
                    df, cls, samples_to_add, base_samples=class_samples
                )
                balanced_df = pd.concat([balanced_df, synthetic_samples], ignore_index=True)
            else:
                # Je≈õli nie ma pr√≥bek danej klasy, generuj losowe
                random_samples = generate_random_samples_for_class(cls, samples_to_add)
                balanced_df = pd.concat([balanced_df, random_samples], ignore_index=True)
    
    # Sprawd≈∫ ko≈Ñcowy rozk≈Çad klas
    final_class_counts = balanced_df[target_col].value_counts()
    logger.info(f"‚úÖ Final class distribution: {dict(final_class_counts)}")
    
    return balanced_df

def generate_synthetic_data(df: pd.DataFrame, n_samples: int) -> pd.DataFrame:
    """
    Generuje syntetyczne dane na podstawie istniejƒÖcych pr√≥bek.
    
    Args:
        df: DataFrame z danymi ≈∫r√≥d≈Çowymi
        n_samples: Liczba pr√≥bek do wygenerowania
        
    Returns:
        pd.DataFrame: DataFrame z syntetycznymi danymi
    """
    if df.empty or n_samples <= 0:
        return pd.DataFrame()
    
    try:
        # Wybierz tylko kolumny numeryczne
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            logger.warning("‚ö†Ô∏è No numeric columns found for synthetic data generation")
            return pd.DataFrame()
        
        # Przygotuj dane do generowania
        X = df[numeric_cols].values
        
        # Normalizuj dane
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # U≈ºyj algorytmu k-najbli≈ºszych sƒÖsiad√≥w do generowania syntetycznych pr√≥bek
        synthetic_samples = []
        
        # Okre≈õl liczbƒô sƒÖsiad√≥w (k)
        k = min(5, len(df) - 1)
        if k <= 1:
            # Je≈õli mamy za ma≈Ço pr√≥bek, u≈ºyj prostszej metody
            for _ in range(n_samples):
                # Wybierz losowƒÖ pr√≥bkƒô
                idx = np.random.randint(0, len(df))
                sample = df.iloc[idx].copy()
                
                # Dodaj losowe zaburzenia do warto≈õci numerycznych
                for col in numeric_cols:
                    if col in sample:
                        noise = np.random.normal(0, 0.1 * df[col].std())
                        sample[col] += noise
                
                synthetic_samples.append(sample)
        else:
            # U≈ºyj algorytmu k-NN
            nbrs = NearestNeighbors(n_neighbors=k).fit(X_scaled)
            
            for _ in range(n_samples):
                # Wybierz losowƒÖ pr√≥bkƒô
                idx = np.random.randint(0, len(df))
                sample = X_scaled[idx]
                
                # Znajd≈∫ k najbli≈ºszych sƒÖsiad√≥w
                _, indices = nbrs.kneighbors([sample])
                
                # Wybierz losowego sƒÖsiada
                neighbor_idx = indices[0][np.random.randint(1, k)]
                neighbor = X_scaled[neighbor_idx]
                
                # Generuj syntetycznƒÖ pr√≥bkƒô jako kombinacjƒô pr√≥bki i sƒÖsiada
                alpha = np.random.random()
                synthetic = sample + alpha * (neighbor - sample)
                
                # Odwr√≥ƒá normalizacjƒô
                synthetic_denorm = scaler.inverse_transform([synthetic])[0]
                
                # Utw√≥rz nowy wiersz DataFrame
                synthetic_row = df.iloc[idx].copy()
                for i, col in enumerate(numeric_cols):
                    synthetic_row[col] = synthetic_denorm[i]
                
                synthetic_samples.append(synthetic_row)
        
        # Utw√≥rz DataFrame z syntetycznych pr√≥bek
        synthetic_df = pd.DataFrame(synthetic_samples)
        
        logger.info(f"‚úÖ Generated {len(synthetic_df)} synthetic samples")
        return synthetic_df
        
    except Exception as e:
        logger.error(f"‚ùå Error generating synthetic data: {e}")
        return pd.DataFrame()

def generate_synthetic_samples_for_class(df: pd.DataFrame, 
                                        target_class: str, 
                                        n_samples: int,
                                        target_col: str = 'direction',
                                        base_samples: Optional[pd.DataFrame] = None) -> pd.DataFrame:
    """
    Generuje syntetyczne pr√≥bki dla okre≈õlonej klasy.
    
    Args:
        df: DataFrame z danymi ≈∫r√≥d≈Çowymi
        target_class: Klasa, dla kt√≥rej generujemy pr√≥bki
        n_samples: Liczba pr√≥bek do wygenerowania
        target_col: Nazwa kolumny zawierajƒÖcej etykiety klas
        base_samples: Opcjonalnie, pr√≥bki bazowe do generowania
        
    Returns:
        pd.DataFrame: DataFrame z syntetycznymi pr√≥bkami
    """
    if df.empty or n_samples <= 0:
        return pd.DataFrame()
    
    try:
        # Je≈õli nie podano pr√≥bek bazowych, u≈ºyj wszystkich pr√≥bek
        if base_samples is None or base_samples.empty:
            base_samples = df.copy()
        
        # Wybierz tylko kolumny numeryczne
        numeric_cols = base_samples.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            logger.warning("‚ö†Ô∏è No numeric columns found for synthetic sample generation")
            return pd.DataFrame()
        
        # Generuj syntetyczne pr√≥bki
        synthetic_samples = []
        
        for _ in range(n_samples):
            # Wybierz losowƒÖ pr√≥bkƒô
            idx = np.random.randint(0, len(base_samples))
            sample = base_samples.iloc[idx].copy()
            
            # Ustaw klasƒô docelowƒÖ
            sample[target_col] = target_class
            
            # Dodaj losowe zaburzenia do warto≈õci numerycznych
            for col in numeric_cols:
                if col in sample and col != target_col:
                    noise = np.random.normal(0, 0.1 * base_samples[col].std())
                    sample[col] += noise
            
            synthetic_samples.append(sample)
        
        # Utw√≥rz DataFrame z syntetycznych pr√≥bek
        synthetic_df = pd.DataFrame(synthetic_samples)
        
        logger.info(f"‚úÖ Generated {len(synthetic_df)} synthetic samples for class '{target_class}'")
        return synthetic_df
        
    except Exception as e:
        logger.error(f"‚ùå Error generating synthetic samples for class '{target_class}': {e}")
        return pd.DataFrame()

def generate_random_data(n_samples: int) -> pd.DataFrame:
    """
    Generuje ca≈Çkowicie losowe dane.
    
    Args:
        n_samples: Liczba pr√≥bek do wygenerowania
        
    Returns:
        pd.DataFrame: DataFrame z losowymi danymi
    """
    try:
        # Utw√≥rz podstawowe kolumny
        data = {
            'timestamp': [datetime.now() - timedelta(hours=i) for i in range(n_samples)],
            'price': np.random.uniform(10, 1000, n_samples),
            'volume': np.random.uniform(1000, 100000, n_samples),
            'rsi': np.random.uniform(0, 100, n_samples),
            'direction': np.random.choice(['long', 'short', 'hold'], n_samples)
        }
        
        # Dodaj dodatkowe kolumny
        data['price_change_24h'] = np.random.uniform(-10, 10, n_samples)
        data['volatility'] = np.random.uniform(0.01, 0.1, n_samples)
        
        # Utw√≥rz DataFrame
        df = pd.DataFrame(data)
        
        logger.info(f"‚úÖ Generated {n_samples} random samples")
        return df
        
    except Exception as e:
        logger.error(f"‚ùå Error generating random data: {e}")
        return pd.DataFrame()

def generate_random_samples_for_class(target_class: str, n_samples: int) -> pd.DataFrame:
    """
    Generuje losowe pr√≥bki dla okre≈õlonej klasy.
    
    Args:
        target_class: Klasa, dla kt√≥rej generujemy pr√≥bki
        n_samples: Liczba pr√≥bek do wygenerowania
        
    Returns:
        pd.DataFrame: DataFrame z losowymi pr√≥bkami
    """
    try:
        # Utw√≥rz podstawowe kolumny
        data = {
            'timestamp': [datetime.now() - timedelta(hours=i) for i in range(n_samples)],
            'price': np.random.uniform(10, 1000, n_samples),
            'volume': np.random.uniform(1000, 100000, n_samples),
            'rsi': np.random.uniform(0, 100, n_samples),
            'direction': [target_class] * n_samples
        }
        
        # Dostosuj warto≈õci w zale≈ºno≈õci od klasy
        if target_class == 'long':
            # Dla klasy 'long' ustaw wy≈ºsze RSI i pozytywne zmiany cen
            data['rsi'] = np.random.uniform(60, 90, n_samples)
            data['price_change_24h'] = np.random.uniform(1, 10, n_samples)
        elif target_class == 'short':
            # Dla klasy 'short' ustaw ni≈ºsze RSI i negatywne zmiany cen
            data['rsi'] = np.random.uniform(10, 40, n_samples)
            data['price_change_24h'] = np.random.uniform(-10, -1, n_samples)
        else:  # 'hold'
            # Dla klasy 'hold' ustaw neutralne RSI i ma≈Çe zmiany cen
            data['rsi'] = np.random.uniform(40, 60, n_samples)
            data['price_change_24h'] = np.random.uniform(-1, 1, n_samples)
        
        # Dodaj dodatkowe kolumny
        data['volatility'] = np.random.uniform(0.01, 0.1, n_samples)
        
        # Utw√≥rz DataFrame
        df = pd.DataFrame(data)
        
        logger.info(f"‚úÖ Generated {n_samples} random samples for class '{target_class}'")
        return df
        
    except Exception as e:
        logger.error(f"‚ùå Error generating random samples for class '{target_class}': {e}")
        return pd.DataFrame()

def augment_time_series_data(df: pd.DataFrame, time_col: str = 'timestamp', value_col: str = 'price') -> pd.DataFrame:
    """
    Augmentuje dane szereg√≥w czasowych.
    
    Args:
        df: DataFrame z danymi szereg√≥w czasowych
        time_col: Nazwa kolumny zawierajƒÖcej czas
        value_col: Nazwa kolumny zawierajƒÖcej warto≈õci
        
    Returns:
        pd.DataFrame: DataFrame z augmentowanymi danymi
    """
    if df.empty or time_col not in df.columns or value_col not in df.columns:
        return df
    
    try:
        # Sortuj dane wed≈Çug czasu
        df_sorted = df.sort_values(by=time_col).copy()
        
        # Utw√≥rz kopiƒô danych z r√≥≈ºnymi transformacjami
        augmented_data = []
        
        # 1. Oryginalne dane
        augmented_data.append(df_sorted.copy())
        
        # 2. Dodaj szum do warto≈õci
        noisy_df = df_sorted.copy()
        noisy_df[value_col] = noisy_df[value_col] * (1 + np.random.normal(0, 0.01, len(noisy_df)))
        augmented_data.append(noisy_df)
        
        # 3. Przesu≈Ñ warto≈õci w czasie
        shifted_df = df_sorted.copy()
        shifted_df[value_col] = shifted_df[value_col].shift(1).fillna(method='bfill')
        augmented_data.append(shifted_df)
        
        # 4. Wyg≈Çad≈∫ warto≈õci
        smoothed_df = df_sorted.copy()
        smoothed_df[value_col] = smoothed_df[value_col].rolling(window=3, min_periods=1).mean()
        augmented_data.append(smoothed_df)
        
        # Po≈ÇƒÖcz wszystkie augmentowane dane
        augmented_df = pd.concat(augmented_data, ignore_index=True)
        
        logger.info(f"‚úÖ Augmented time series data: {len(df)} ‚Üí {len(augmented_df)} samples")
        return augmented_df
        
    except Exception as e:
        logger.error(f"‚ùå Error augmenting time series data: {e}")
        return df

def save_augmented_data(df: pd.DataFrame, csv_path: str) -> bool:
    """
    Zapisuje augmentowane dane do pliku CSV.
    
    Args:
        df: DataFrame z augmentowanymi danymi
        csv_path: ≈öcie≈ºka do pliku CSV
        
    Returns:
        bool: True, je≈õli zapis siƒô powi√≥d≈Ç, False w przeciwnym razie
    """
    if df.empty:
        logger.warning("‚ö†Ô∏è Cannot save empty DataFrame")
        return False
    
    try:
        # Utw√≥rz katalog, je≈õli nie istnieje
        os.makedirs(os.path.dirname(os.path.abspath(csv_path)), exist_ok=True)
        
        # Zapisz dane do pliku CSV
        df.to_csv(csv_path, index=False)
        
        logger.info(f"‚úÖ Saved {len(df)} samples to {csv_path}")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error saving augmented data: {e}")
        return False

